---
title: 'COVID‑19 Outcomes Across Economic Groups: A Cross‑Country Data Analysis'
output:
  html_document: default
  word_document: default
  pdf_document: default
date: "2025-06-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Part 1: Data wrangling and integration

Loading relevant r packages:
```{r}
library(tidyverse)
library(here)
```


Firstly we will import each of the three datasets and examine the tables columns and data types.

Importing "Covid.Data" table and viewing the table:
```{r}
#import Covid dataset
Covid.data <- read.csv(here("Raw Data", "Covid-data.csv"),)

head(Covid.data)
```

The "Covid.data" table appears to show the amount of new covid cases and deaths classified by date and country while also displaying the countries gdp per capita and total population.


```{r}
#Selecting rows with missing data
Covid.data_missing <- Covid.data[!complete.cases(Covid.data), ]
Covid.data_missing
```
As we can see there are 11 rows with missing data in this table. These NA values take place within the "new_deaths" and "total_deaths" columns. Interestingly they all appear on rows ending in 1, eg 101, 251 etc.


```{r}
# Start with a clean copy
covid.data_tidy <- Covid.data %>%
  arrange(location, date) %>%   # ensure correct chronological order
  mutate(row_id = row_number())

# Impute missing total_deaths using cumulative logic
# Identify rows where total_deaths is missing
missing_total <- covid.data_tidy %>%
  filter(is.na(total_deaths)) %>%
  pull(row_id)

# Reconstruct total_deaths using previous day's cumulative total
covid.data_tidy <- covid.data_tidy %>%
  mutate(
    total_deaths = if_else(
      is.na(total_deaths),
      lag(total_deaths) + new_deaths,
      total_deaths
    )
  )

# Inspect affected rows
covid.data_tidy %>%
  slice(sort(c(missing_total - 1, missing_total)))
```

For missing new deaths we can get the total deaths from the next day and subtract them by the total deaths in the row with the missing new deaths to get the missing value.

```{r}
#calculate missing values for new deaths
# Identify rows where new_deaths is missing
missing_new <- covid.data_tidy %>%
  filter(is.na(new_deaths)) %>%
  pull(row_id)

# Reconstruct new_deaths using difference between cumulative totals
covid.data_tidy <- covid.data_tidy %>%
  mutate(
    new_deaths = if_else(
      is.na(new_deaths),
      total_deaths - lag(total_deaths),
      new_deaths
    )
  )

# Inspect affected rows to check new deaths columns
covid.data_tidy %>%
  slice(sort(c(missing_new - 1, missing_new)))


```

For UK on 2020-01-19 which has 0 cases and 0 total cases we must update total_deaths and new_deaths by changing their value to 0 since it is impossible to die from covid if you do not have covid.

```{r}
# Filter row based on location and date and replace new and total deaths values to 0
covid.data_tidy <- covid.data_tidy %>%
  mutate(
    total_deaths = if_else(
      location == "United Kingdom" &
      date == as.Date("2020-01-19") &
      is.na(total_deaths),
      0,
      total_deaths
    ),
    new_deaths = if_else(
      location == "United Kingdom" &
      date == as.Date("2020-01-19") &
      is.na(new_deaths),
      0,
      new_deaths
    )
  )


# Inspect affected rows
covid.data_tidy %>%
  filter(location == "United Kingdom",
         as.Date(date) == as.Date("2020-01-19"))

  
```
For the row where location is United States and date is 2020-07-03 total deaths and new deaths are both missing and there are a number of total cases so we will need to calculate the missing values using data from the previous and subsequent days.
To find the missing total deaths we can subtract the new deaths from the total deaths on the next date.
To find the missing new deaths we can subtract the previous total deaths from the newly calculated total deaths.
```{r}
# --- 1. Calculate missing total_deaths for 2020-05-01 ---

# Values from 2020-05-02
us_total_0502 <- covid.data_tidy %>%
  filter(location == "United States",
         date == as.Date("2020-05-02")) %>%
  pull(total_deaths)

us_new_0502 <- covid.data_tidy %>%
  filter(location == "United States",
         date == as.Date("2020-05-02")) %>%
  pull(new_deaths)

# Update total_deaths for 2020-05-01
covid.data_tidy <- covid.data_tidy %>%
  mutate(
    total_deaths = if_else(
      location == "United States" &
      date == as.Date("2020-05-01") &
      is.na(total_deaths),
      us_total_0502 - us_new_0502,
      total_deaths
    )
  )


# --- 2. Calculate missing new_deaths for 2020-05-01 ---

# Values from 2020-05-01 and 2020-04-30
us_total_0501 <- covid.data_tidy %>%
  filter(location == "United States",
         date == as.Date("2020-05-01")) %>%
  pull(total_deaths)

us_total_0430 <- covid.data_tidy %>%
  filter(location == "United States",
         date == as.Date("2020-04-30")) %>%
  pull(total_deaths)

# Update new_deaths for 2020-05-01
covid.data_tidy <- covid.data_tidy %>%
  mutate(
    new_deaths = if_else(
      location == "United States" &
      date == as.Date("2020-05-01") &
      is.na(new_deaths),
      us_total_0501 - us_total_0430,
      new_deaths
    )
  )

#view column to check updated values
covid.data_tidy %>%
  filter(location == "United States",
         date == as.Date("2020-05-01"))
```
Now we will check the covid.data_tidy table again to see if all the missing values have been filled.

```{r}
#Check for missing values
covid.data_tidy[!complete.cases(covid.data_tidy), ]
```
And if all the code chunks have been executed in sequential order we can see there are no more missing values for the covid.data table.

Now we will import data from the countrylockdowndates table

```{r}
CountryLockdowndates <- read.csv(here("Raw Data", "CountryLockdowndates.csv"))
head(CountryLockdowndates, 10)
```
This table shows a list of countries, the type of lockdown they had during covid and when they went on lockdown.

selecting rows with missing data:
```{r}
#Select rows with missing data
CountryLockdowndates_missing <- CountryLockdowndates[!complete.cases(CountryLockdowndates), ]
CountryLockdowndates_missing
```

This shows that the table country lockdown dates has no missing values.

Finally we will now import the final data set worldwidevaccinedata

```{r}
#Import worldwide vaccine data table
WorldwideVaccineData <- read.csv(here("Raw Data", "WorldwideVaccineData.csv"), header=TRUE)
head(WorldwideVaccineData)
```
This table shows a list of countries statistics relating to the proportion of their population who have been fully and partially vaccinated against covid.

selecting rows with missing data:
```{r}
#Select missing data
vaccine_missing <- WorldwideVaccineData[!complete.cases(WorldwideVaccineData), ]
vaccine_missing
```
Since 0 rows are selected this missing there is no missing data in this table.

Before we can join these three data sets into one table we need to convert the different date columns into the formats. 

At the moment the CountryLockdowndates table has dates in the format dd/mm/yyyy, while the covid.data_tidy table has dates in the format yyyy-mm-dd.
To make things consistent we will convert the date format int eh CountryLockdowndates table to the universal date format of yyyy-mm-dd.

```{r}
#Converting CountryLockdowndates dates column to yyyy-mm-dd

for (index in seq_along(CountryLockdowndates[,3])){
  date <- CountryLockdowndates[index ,3]
  if (date != ""){
    input_date <- as.Date(date, format = "%d/%m/%Y")
    CountryLockdowndates[index, 3] <- format(input_date, "%Y-%m-%d")
  }
}
head(CountryLockdowndates, 10)
```

Now we will rename the country.region column name so we can join it with the location column in the covid.data_tidy table.
```{r}
#renaming CountryLockdowndates columns country.region to location and date to lockdown date
names(CountryLockdowndates)[names(CountryLockdowndates) == "Country.Region"] <- "location"
names(CountryLockdowndates)[names(CountryLockdowndates) == "Date"] <- "lockdown_date"

```

Now we will remove columns from the countrylockdowndates table that we do not want to use and display all of the locations that are in duplicate.
```{r}
# add new data frame to manipulate
lock_down <- CountryLockdowndates
#select all countries with duplicates
lock_down <- lock_down %>%
  arrange(location, lockdown_date) %>%
  filter(duplicated(location)== TRUE)
#select to only display location and lockdown_date
lock_down <- subset(lock_down, select = c(location, lockdown_date))
#Display first 10 rows
head(lock_down,10)
```
As we can see Australia, Canada, China, France, Netherlands, US, United Kingdom have multiple dates for lockdown_date, this is due to the different regions/ states within the countries having their own dates for lockdowns. 
To tidy our data in the lock_down table we will only have 1 row for each country and the lockdown date will be the earliest within that countries provences.

```{r}
#add new data frame to manipulate
lock_down <- CountryLockdowndates
#Remove duplicate countries
lock_down <- lock_down %>%
  arrange(location, lockdown_date) %>%
  filter(duplicated(location)== FALSE)
#select to only display location and lockdown_date
lock_down <- subset(lock_down, select = c(location, lockdown_date))
#Assign earliest lockdown dates to duplicate countries
lock_down[9,2] <- "2020-03-24" #Australia
lock_down[32,2] <- "2020-03-14" #Canada
lock_down[36,2] <- "2020-01-23" #China
lock_down[61,2] <- "2020-03-16" #France
lock_down[120,2] <- "2020-03-16" #Netherlands
lock_down[170,2] <- "2020-03-13" #US
lock_down[174,2] <- "2020-03-18" #United Kingdom
```



Now We will rename the country column in worldwidevaccinedata to location too.

```{r}
#renaming worldwidevaccinedata country column to location
names(WorldwideVaccineData)[names(WorldwideVaccineData) == "Country"] <- "location"
```

Now that the dates in both tables have the same format now we can join the three tables. To do this we will perform multiple inner joins joining on the location.

```{r}
#inner join covid.data_tidy to worldwidevaccinedata on location column
covid_data_vaccine_join <- inner_join(covid.data_tidy, WorldwideVaccineData, by = "location")
head(covid_data_vaccine_join)
```

Now we will inner join our covid_data_vaccine_join table to countrylockdowndates table.

```{r}
#Joining covide_data_vaccine_join with countrylockdowndates
covid_data_joined <- inner_join(covid_data_vaccine_join, lock_down, by = "location")

head(covid_data_joined)
```
Now that all the tables have been joined we can now remove the columns we are not interested in.

```{r}
#remove columns that are not needed
covid_data_joined <- subset(covid_data_joined, select = -c(Doses.administered.per.100.people, X..of.population.vaccinated, row_id))
#rename columns
names(covid_data_joined)[names(covid_data_joined) == "Total.doses.administered"] <- "total_doses_administered"
names(covid_data_joined)[names(covid_data_joined) == "X..of.population.vaccinated"] <- "%_of_population_fully_vaccinated"
head(covid_data_joined)
```
Now we will convert our date and lockdown_date columns to date format.
```{r}
#Convert date column from chr data type to date data type
covid_data_joined <- mutate(covid_data_joined, date = as.Date(date, format = "%Y-%m-%d"))
#Convert lockdown_date column from chr data type to date data type
covid_data_joined <- mutate(covid_data_joined, lockdown_date = as.Date(lockdown_date, format = "%Y-%m-%d"))
#check for errors or missing values
covid_data_joined_missing <- covid_data_joined[!complete.cases(covid_data_joined), ]
head(covid_data_joined_missing)
```
It appears that some date columns are in the incorrect format and will need to be changed to the correct format.

```{r}
#Assigning loop output to a new variable
date_correct_loop <- covid_data_joined
#For loop to search date column to find na and replace it with date from previous index +1 day
for(index in seq_along(date_correct_loop[,2])){
  if(is.na(date_correct_loop[index,2])){
    date_correct_loop[index,2] <- date_correct_loop[index-1,2]+1
  }
}
#Check for missing values
date_correct_loop[!complete.cases(date_correct_loop), ]
```
Now we can check if the dates have been correctly assigned.
```{r}
#Check previous missing indexes for correct date changes
date_correct_loop[c(162, 163, 164, 165, 166, 213, 214, 215), ]
```
```{r}
#Examine case/ death columns for negative values
if (count(filter(date_correct_loop, total_cases < 0)) >0){
  print("Negative values in: total_cases")
}
if (count(filter(date_correct_loop, new_cases < 0)) >0){
  print("Negative values in: new_cases")
}
if (count(filter(date_correct_loop, total_deaths < 0)) >0){
  print("Negative values in: total_deaths")
}
if (count(filter(date_correct_loop, new_deaths < 0)) >0){
  print("Negative values in: new_deaths")
}
```
Since we have negative values in our new_cases and new_deaths columns we will need to find them and correct them.

```{r}
#Select rows with negative data
negative_values <- filter(date_correct_loop, new_deaths <0 | new_cases <0)
negative_values
#Examine dates before the rows with negative values to check if negative values can be multiplied by -1
filter(date_correct_loop, date == "2020-06-05" & location == "France")
filter(date_correct_loop, date == "2020-06-24" & location == "Italy")
filter(date_correct_loop, date == "2020-04-18" & location == "Spain")
filter(date_correct_loop, date == "2020-05-24" & location == "Spain")
```
As we can see here with the different extracted data frames the rows with negative values have affected the corresponding total column as well so we will need t o multiple the negative value by -1 and add the new value to the total column to fix it.

```{r}
#Assign loop variable for negative values loop
negative_val_loop <- date_correct_loop
#For loop to search for rows with negative values in new_cases, multiply the value be -1 and add the value to correct the corresponding total column
for(i in seq_along(negative_val_loop[,4])){
 if (negative_val_loop[i,4] < 0){
   negative_val_loop[i,4] <- negative_val_loop[i,4] * -1
   negative_val_loop[i,3] <- negative_val_loop[i,3] + negative_val_loop[i,4]
   
 }
}
#Check for negative values in new_cases
filter(negative_val_loop, new_cases < 0)

```

Now we will perform the same action to the negative values in the new_deaths column.

```{r}
#For loop to search for rows with negative values in new_deaths, multiply the value be -1 and add the value to correct the corresponding total column
for(i in seq_along(negative_val_loop[,6])){
 if (negative_val_loop[i,6] < 0){
   negative_val_loop[i,6] <- negative_val_loop[i,6] * -1
   negative_val_loop[i,5] <- negative_val_loop[i,5] + negative_val_loop[i,6]
   
 }
}
#Check for negative values in new_deaths
filter(negative_val_loop, new_cases < 0)
```
Now we will recalculate the total_cases column using the new_case column to ensure no counting errors have taken place in the table.


```{r}
# Initialize first row of dataset
negative_val_loop[1, 3] <- negative_val_loop[1, 4]

prev_country <- negative_val_loop[1, 1]
prev_date    <- negative_val_loop[1, 2]

for (i in 2:nrow(negative_val_loop)) {

  current_country <- negative_val_loop[i, 1]
  current_date    <- negative_val_loop[i, 2]

  # Case 1: new country → reset cumulative
  if (current_country != prev_country) {
    negative_val_loop[i, 3] <- negative_val_loop[i, 4]
  # Case 2: same country and first non-zero total_cases → convert total_cases to new_cases
  } else if (negative_val_loop[i-1,3] == 0 &&
             negative_val_loop[i-1,4] == 0) {
    negative_val_loop[i,3] <- negative_val_loop[i,4]
  # Case 3: same country AND consecutive date → cumulative update
  } else if (current_date == prev_date + 1) {
    negative_val_loop[i, 3] <- negative_val_loop[i - 1, 3] + negative_val_loop[i, 4]

  # Case 4: same country BUT date skipped → keep existing total_cases unless new_cases > total_cases - previous total_cases then add new_cases and previous total_cases together 
  } else { if (negative_val_loop[i,3] < negative_val_loop[i-1,3] +
               negative_val_loop[i,4]){
    negative_val_loop[i,3] <- negative_val_loop[i,4] + negative_val_loop[i-1,3]
  }
   
  }

  # update trackers
  prev_country <- current_country
  prev_date    <- current_date
}


```

Now the the total_cases column is incrementing correctly we will now correct the values in the total_deaths column.


```{r}
# Initialize first row of dataset
negative_val_loop[1, 5] <- negative_val_loop[1, 6]

prev_country <- negative_val_loop[1, 1]
prev_date    <- negative_val_loop[1, 2]

for (i in 2:nrow(negative_val_loop)) {

  current_country <- negative_val_loop[i, 1]
  current_date    <- negative_val_loop[i, 2]

  # Case 1: new country → reset cumulative
  if (current_country != prev_country) {
    negative_val_loop[i, 5] <- negative_val_loop[i, 6]
  # Case 2: same country and first non-zero total_deaths → convert total_deaths to new_deaths
  } else if (negative_val_loop[i-1,5] == 0 &&
             negative_val_loop[i-1,6] == 0) {
    negative_val_loop[i,5] <- negative_val_loop[i,6]
  # Case 3: same country AND consecutive date → cumulative update
  } else if (current_date == prev_date + 1) {
    negative_val_loop[i, 5] <- negative_val_loop[i - 1, 5] + negative_val_loop[i, 6]

  # Case 4: same country BUT date skipped → keep existing total_deaths unless new_deaths > total_cases - previous total_deaths then add new_deaths and previous total_deaths together 
  } else { if (negative_val_loop[i,5] < negative_val_loop[i-1,5] +
               negative_val_loop[i,6]){
    negative_val_loop[i,5] <- negative_val_loop[i,6] + negative_val_loop[i-1,5]
  }
   
  }

  # update trackers
  prev_country <- current_country
  prev_date    <- current_date
}


```

Lets check our data again for any negative values.

```{r}
#Examine case/ death columns for negative values
filter(negative_val_loop, total_cases < 0 |
         total_deaths < 0 |
         new_cases < 0 |
         new_deaths <0
       )
```
Lets produce a quick plot as a final check to see if there are any irregularties in our data.

```{r}
#Plot a line graph using the clean covid data examining new cases over time
ggplot(data = negative_val_loop, aes(x = date, y = new_cases, group = location, color = location))+
  geom_line(linewidth = 0.5)+
  #Split plot by country, give each plot its own scale
  facet_grid(rows = vars(location), scales = "free")
  
```
As shown in the plot, there is a value in the Iran data that appears inconsistent: new cases drop from several thousand to zero and then return to several thousand the very next day. This pattern is unlikely to reflect real transmission dynamics, so it warrants closer examination to determine whether it represents a reporting delay, a data entry error, or missing information.

```{r}
#filter data by rows with 0 new_cases and new_deaths when total cases are above 100.
negative_val_loop %>%
filter( new_cases == 0 & new_deaths == 0 & total_cases > 100)
```
From the plot above, we can see that there are 40 dates across four countries where both new cases and new deaths are recorded as zero, despite surrounding days showing thousands of cases. This pattern is highly unlikely to reflect real epidemiological conditions and instead suggests missing or incomplete reporting. There are a couple of reasonable approaches to address this anomaly. One option is to verify the correct figures using official government or public‑health sources. Alternatively, we could omit these rows from the dataset; given the size of the full dataset, removing a small number of clearly inaccurate entries is unlikely to materially affect the overall analysis.

```{r}
#Delete outlier data rows
negative_val_loop_outliers_removed <- negative_val_loop %>%
  filter(!(new_cases == 0 & new_deaths == 0 & total_cases > 100))
```

We will now perform the same check for new_deaths.

```{r}
#Plot a line graph using the clean covid data examining new cases over time
ggplot(data = negative_val_loop_outliers_removed, aes(x = date, y = new_cases, group = location, color = location))+
  geom_line(linewidth = 0.5)+
  #Split plot by country, give each plot its own scale
  facet_grid(rows = vars(location), scales = "free")
```
Now we can assign our clean data to a new variable name.

```{r}
#Reassign cleaned data to a new variable
covid_data_clean <- negative_val_loop_outliers_removed
```

Finally we have our cleaned and joined dataset ready for analysis.

### Part 2: Data visualisation and analysis

First we will create a plot to examine the trend of new cases in each country.

```{r}
#Plot a line graph using the clean covid data examining new cases over time
ggplot(data = covid_data_clean, aes(x = date, y = new_cases, group = location, color = location))+
  geom_line(linewidth = 0.5)+
  #Scale x-axis by month
  scale_x_date(date_breaks = "1 month", date_labels = "%b-%y")+
  #Split plot by country, give each plot its own scale
  facet_grid(rows = vars(location), scales = "free")+
  #Add title
  labs(title = "Countries New Covid Infections By Calendar Date", colour = "Location")+
  #Add vertical lines representing when lockdowns first began in each of the countries
  geom_vline(data = filter(covid_data_clean, location == "Australia"), 
aes(xintercept = covid_data_clean[1,11]))+
  geom_vline(data = filter(covid_data_clean, location == "France"), aes(xintercept = covid_data_clean[213,11]))+
  geom_vline(data = filter(covid_data_clean, location == "Iran"), aes(xintercept = covid_data_clean[400,11]))+
  geom_vline(data = filter(covid_data_clean, location == "Italy"), aes(xintercept = covid_data_clean[588,11]))+
  geom_vline(data = filter(covid_data_clean, location == "Spain"), aes(xintercept = covid_data_clean[808,11]))+
  #Add x-axis label
  xlab("Date")+
  #Add y-axis label
  ylab("New Cases")
  
```
When examining the plot above, we can see that each country experiences a clear peak in new daily cases around late March to early April, followed by a gradual decline. The black vertical line marks the date each country implemented its first lockdown. For most countries, case numbers begin to fall within roughly a month of these initial restrictions, although the rate of decline varies. Some countries show a sharp and immediate drop, while others display a more gradual reduction, reflecting differences in timing, enforcement, and public adherence to the measures.

```{r}
#Plot a line graph using the clean covid data examining new cases over time
ggplot(data = filter(covid_data_clean, location == "Australia"), aes(x = date, y = new_cases, group = location, color = location))+
  geom_line(linewidth = 0.75)+
  #Scale x-axis by month
  scale_x_date(date_breaks = "1 month", date_labels = "%b-%y")+
  #Add title
  labs(title = "Australia's New Covid Infections By Calendar Date")+
  #Add vertical lines representing when lockdowns first began in each of the countries
  geom_vline(data = filter(covid_data_clean, location == "Australia"), aes(xintercept = covid_data_clean[1,11]))+
   #Add x-axis label
  xlab("Date")+
  #Add y-axis label
  ylab("New Cases")

```
In Australia, the data shows a sharp increase in cases during mid‑ to late‑March. On March 20, Australia closed its international borders and introduced social‑distancing laws as part of a zero‑COVID suppression strategy, followed shortly after by the rollout of lockdown measures on March 24. Following these interventions, daily case numbers declined rapidly, falling to almost zero throughout April and May. A renewed spike emerged in July, driven by an outbreak linked to Victoria’s hotel quarantine system, which marked the beginning of the country’s second wave.


```{r}
#Plot a line graph using the clean covid data examining new cases over time
ggplot(data = filter(covid_data_clean, location == "France"), aes(x = date, y = new_cases, group = location, color = location))+
  geom_line(linewidth = 0.75, colour = "darkkhaki")+
  #Scale x-axis by month
  scale_x_date(date_breaks = "1 month", date_labels = "%b-%y")+
  #Add title
  labs(title = "France's New Covid Infections By Calendar Date")+
  #Add vertical lines representing when lockdowns first began in each of the countries
  geom_vline(data = filter(covid_data_clean, location == "France"), aes(xintercept = covid_data_clean[213,11]))+
   #Add x-axis label
  xlab("Date")+
  #Add y-axis label
  ylab("New Cases")

```
In France, the data shows a spike in cases similar to Australia’s trend, although the scale is significantly larger, with case numbers reaching roughly ten times higher. France implemented its lockdown measures over several days, and because daily cases were already elevated at the time restrictions began, there was a noticeable lag before case numbers started to decline. The spike observed in mid‑May likely reflects the easing of restrictions, including the reopening of schools, which increased opportunities for transmission.


```{r}
#Plot a line graph using the clean covid data examining new cases over time
ggplot(data = filter(covid_data_clean, location == "Iran"), aes(x = date, y = new_cases, group = location, color = location))+
  geom_line(linewidth = 0.75, colour = "aquamarine3")+
  #Scale x-axis by month
  scale_x_date(date_breaks = "1 month", date_labels = "%b-%y")+
  #Add title
  labs(title = "Iran's New Covid Infections By Calendar Date")+
  #Add vertical lines representing when lockdowns first began in each of the countries
  geom_vline(data = filter(covid_data_clean, location == "Iran"), aes(xintercept = covid_data_clean[400,11]))+
   #Add x-axis label
  xlab("Date")+
  #Add y-axis label
  ylab("New Cases")

```
In Iran, the data shows an initial spike in cases in early March, followed by a brief decline after lockdown measures were introduced. However, daily cases rose sharply again, surpassing 2,000 on March 25 and peaking in early April. Once cases began to fall in early April, restrictions were eased, but this relaxation was followed by a renewed surge in infections between May and June. This pattern highlights how early easing of restrictions can contribute to subsequent waves of transmission.
```{r}
#Plot a line graph using the clean covid data examining new cases over time
ggplot(data = filter(covid_data_clean, location == "Italy"), aes(x = date, y = new_cases, group = location, color = location))+
  geom_line(linewidth = 0.75, colour = "deepskyblue1")+
  #Scale x-axis by month
  scale_x_date(date_breaks = "1 month", date_labels = "%b-%y")+
  #Add title
  labs(title = "Italy's New Covid Infections By Calendar Date")+
  #Add vertical lines representing when lockdowns first began in each of the countries
  geom_vline(data = filter(covid_data_clean, location == "Italy"), aes(xintercept = covid_data_clean[588,11]))+
  #Add x-axis label
  xlab("Date")+
  #Add y-axis label
  ylab("New Cases")

```
In Italy, the first regional lockdowns targeted public spaces and social venues such as bars and pubs, prompting significant public frustration. As cases continued to rise, the government escalated its response by implementing a nationwide lockdown on March 21, closing all non‑essential industries, restricting movement, and shutting public parks and playgrounds. The graph shows a clear decline in daily case numbers following these measures, indicating that the restrictions had a substantial impact on transmission. Restrictions were gradually eased on May 18, with most businesses reopening and domestic travel permitted once again.

```{r}
#Plot a line graph using the clean covid data examining new cases over time
ggplot(data = filter(covid_data_clean, location == "Spain"), aes(x = date, y = new_cases, group = location, color = location))+
  geom_line(linewidth = 0.75, colour = "mediumorchid1")+
  #Scale x-axis by month
  scale_x_date(date_breaks = "1 month", date_labels = "%b-%y")+
  #Add title
  labs(title = "Spain's New Covid Infections By Calendar Date")+
  #Add vertical lines representing when lockdowns first began in each of the countries
  geom_vline(data = filter(covid_data_clean, location == "Spain"), aes(xintercept = covid_data_clean[213,11]))+
  #Add x-axis label
  xlab("Date")+
  #Add y-axis label
  ylab("New Cases")

```
In Spain, the first national lockdown was introduced on March 14, with restrictions tightened further on March 30 to limit movement for all non‑essential workers. When examining the graph, we see daily cases peaking around the time these stricter measures were implemented, followed by a sharp decline as the restrictions took effect. Lockdown measures were later eased on June 21, but cases began rising again in July, prompting several regions to reintroduce targeted restrictions.
Having reviewed the daily case trends for each country, we can now explore whether a country’s economic status influences its COVID‑19 outcomes. To begin, we calculate the mean GDP per capita across all countries in the dataset.

```{r}
#Calculate mean GDP of locations
mean_gdp <- covid_data_clean %>%
  summarise(mean_gdp = mean(gdp_per_capita)) %>%
  pull(mean_gdp)
mean_gdp
 
  
```
Now we can create a new column that classifies each country based on how its GDP per capita compares to the global average. Countries with GDP values above the mean are labelled “Higher”, while those below the mean are labelled “Lower.” This grouping allows us to analyse infection and death rates across broad economic categories in a consistent and interpretable way.

```{r}
#Assigning new column to data frame which describes if the locations GDP per capita is higher or lower than the average called GDP_status
covid_data_clean <- covid_data_clean %>%
  mutate(
    GDP_status = ifelse(
      gdp_per_capita >= mean_gdp, #mean of GDP_per_capita
      "Higher", 
      "Lower"
    )
  )
#Check data frame to see if new column has been added as intended
head(covid_data_clean)
```
Now we can add two new variables to support our analysis. The first, daily infected case rate, is calculated as new_cases divided by each country’s population. The second, daily death rate, is computed as new_deaths divided by the population. These metrics standardise case and death counts across countries of different sizes, allowing for more meaningful comparisons.


```{r}
#Adding daily_infected_case_rate column
covid_data_clean <- covid_data_clean%>%
  mutate(
   daily_infected_case_rate = (new_cases / population) 
  )

#Adding daily_death_rate column
covid_data_clean <- covid_data_clean%>%
  mutate(
   daily_death_rate = (new_deaths / population) 
  )
head(covid_data_clean)
```
Now that the data is prepared, we can visualise how infection rates differ across economic groups. The following plot illustrates the relationship between daily infected case rates and GDP status, allowing us to compare trends between higher‑ and lower‑GDP countries over time.

```{r}
#Generate plot of the relationship between the daily infected case rate within different GDP groups
covid_data_clean %>%
  #aggregate data
  group_by(date, GDP_status) %>%
  #Calculate mean_infected_rate value for y-axis
  summarise(mean_infected_rate = mean(daily_infected_case_rate, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_infected_rate, color = GDP_status)) +
  geom_line(linewidth = 0.5) +
  scale_x_date(date_breaks = "1 month", date_labels = "%b-%y") +
  labs(title = "Average Daily Infection Rate by GDP Group",
       y = "Mean Daily Infection Rate",
       x = "Date",
       colour = "GDP Status")

```

As we can see from the graph, countries with lower GDP status tend to experience higher daily infected case rates. This suggests that economic capacity may play a role in shaping how effectively countries can limit transmission.
To build on this, the next step is to examine whether the same pattern appears in mortality outcomes. Below, I plot the relationship between the daily death rate and GDP group to assess whether lower‑GDP countries also experience disproportionately higher fatality rates.

```{r}
#Generate plot of the relationship between the daily death rate within different GDP groups
covid_data_clean %>%
  #aggregate data
  group_by(date, GDP_status) %>%
  #Calculate mean_death_rate value for y-axis
  summarise(mean_death_rate = mean(daily_death_rate, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_death_rate, color = GDP_status)) +
  geom_line(linewidth = 0.5) +
  scale_x_date(date_breaks = "1 month", date_labels = "%b-%y") +
  labs(title = "Average Daily Death Rate by GDP Group",
       y = "Mean Daily Death Rate",
       x = "Date",
       colour = "GDP Status")

```

Countries with lower GDP per capita show consistently higher daily death rates compared with higher‑GDP countries, although this gap is less pronounced than the difference observed in daily infection rates. These patterns may reflect structural advantages in higher‑GDP countries, such as stronger healthcare systems, greater treatment capacity, and more effective public‑health infrastructure. Higher‑income countries also tend to have broader access to health education and preventive measures, which can reduce transmission and improve patient outcomes.


## References
[1]Group of Eight (Australian universities) (April 2020). A Roadmap to Recovery -- A Report for the Nation (PDF) (Report).
[2]"Judicial Inquiry into Hotel Quarantine Program". www.premier.vic.gov.au. Victorian Government. 2 July 2020. Retrieved 28 January 2021.
[3] "France to extend coronavirus emergency for two months". Al Jazeera. 2 May 2020. Archived from the original on 5 May 2020. Retrieved 4 May 2020.
[4]"REPLAY. Coronavirus : prolongation du confinement jusqu'au 11 mai, tests, masques... Revivez l'allocution d'Emmanuel Macron". France Info. 13 April 2020. Archived from the original on 14 April 2020. Retrieved 13 April 2020.
[5]Arsalan Shahla (6 May 2020). "Iran's Coronavirus Cases Creep Up After Officials Ease Lockdown". Bloomberg.
[6]"Coronavirus: Italy's Conte offers hope as travel restrictions end". BBC News. 3 June 2020. Retrieved 7 October 2020.
[7]"Spain poised to tighten coronavirus lockdown after record daily toll". MSN. Retrieved 2020-03-29.
[8]"Coronavirus: Spain drives fears of European 'second wave'". BBC. 2020-07-25.
[9] "Spain won't declare another national state of alarm, allows regions to lockdown if necessary". Euroactiv. 2020-08-26.
